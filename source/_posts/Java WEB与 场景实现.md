---
title: 复习整理————Java WEB
date: 2018-07-26 18:15:35
tags: [面试题]
categories: 经验总结

---

# Java WEB与 场景实现

## 大数据 找数，排序，计数，去重
思想：
**MapReduce  分治**
**bitmap位图**，用小信息代表大信息。如（2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）就能代表对象是否存在
**位图方法：**
使用位图法判断整形数组**是否存在重复** 
判断集合中存在重复是常见编程任务之一，当集合中数据量比较大时我们通常希望少进行几次扫描，这时双重循环法就不可取了。

位图法比较适合于这种情况，它的做法是按照集合中**最大元素max创建一个长度为max+1的新数组**，然后再次扫描原数组，遇到几就给新数组的第几位置上1，如遇到5就给新数组的第六个元素置1，这样下次再遇到5想置位时发现新数组的第六个元素已经是1了，这说明这次的数据肯定和以前的数据存在着重复。这种给新数组初始化时置零其后置一的做法类似于位图的处理方法故称位图法。它的运算次数最坏的情况为2N。如果已知数组的最大值即能事先给新数组定长的话效率还能提高一倍。


[Hash Top-K bit解决][1]
[参考][2]

**1.找出俩文件，共同url字段**
**限制：**内存，不可能全部数读入内存
**方法1分治法：**，将A，B文件hash(url)%1000 分到1000个小文件中（2000个），然后比较a0与b0...a999与b999，用hash_set比较小文件
**方法1Bloom filter：**有一定容错率，用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。

**2.找出十文件中，（query）字段按频率排序**
**方法1**：先hash（query）%10 得到10文件，分别对其haspmap统计次数，然后快排/堆/并归，得到10个排好的文件，再对10文件并归成1个
**方法2**：query的种类有限，直接将采用trie树/hash_map等直接来统计每个query出现的次数，然后排序 

**3.大文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。（高频100词）**
方法：hash细分到大小合适的小文件，对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词，把这5000个文件进行归并（类似与归并排序）的过程了。

**海量日志数据，提取出某日访问百度次数最多的那个IP**
算法思想：**分而治之+Hash**
1.IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理； 
2.可以考虑采用“分而治之”的思想，按照IP地址的**Hash(IP)%1024值**，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；
3.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；
4.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；

7、一个数，如何快速判断这个数是否在那40亿个数unsigned int当中？

与上第6题类似，我的第一反应时快速排序+二分查找。以下是其它更好的方法：
方案1：oo，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

dizengrong：
方案2：这个问题在《编程珠玑》里有很好的描述，大家可以参考下面的思路，探讨一下：
又因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；
这里我们把40亿个数中的每一个用32位的二进制来表示
假设这40亿个数开始放在一个文件中。

然后将这40亿个数分成两类:
1.最高位为0
2.最高位为1
并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；
与要查找的数的最高位比较并接着进入相应的文件再查找

再然后把这个文件为又分成两类:
1.次最高位为0
2.次最高位为1

并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；
与要查找的数的次最高位比较并接着进入相应的文件再查找。
.......
以此类推，就可以找到了,而且时间复杂度为O(logn)，方案2完。





## 请求的过滤 

过滤器，在Web中称之为Filter，通过配置多个过滤器，Web系统可以对所有的Servlet请求进行一层一层的过滤，以完成一些特殊的功能。
例如常用的**资源访问权限控制**、**特殊字符以及敏感词过滤**、**响应信息压缩**等功能。
[Web过滤器详解][3]

**第一步：**定义一个**SecurityFilter类，并继承javax.servlet.Filter接口**
init方法在Web容器启动时就会执行，doFilter在每个Servlet请求的时候执行。
**第二步：**在web.xml中添加过滤器的配置信息

在Servlet规范中，有 3个关于过滤器的核心接口，他们分别是
**Filter：** Web系统实现此接口，并配置到web.xml中，满足条件的所有Servlet请求就都将经过此过滤器
**FilterConfig：**该接口实现类的对象中存储了有关Filter的一些配置信息，其中包括了过滤器名称、初始化的参数，并且关联了Servlet的上下文，过滤器可以根据此对象进行初始化。
**FilterChain：** 该接口只提供了一个doFilter方法，通过该方法，当前过滤器可以找到下一个过滤器，并执行其doFIlter方法，也就是说，FilterChain对象中设计了一套过滤器存储链，用来设定过滤器的执行顺序。

## 流量削峰 （不就是类似秒杀么，小case）
1、系统基于微服务的架构设计，弹性**扩展瓶颈模块**服务器资源；
2、接入层以及各微服务模块极大的**用好cache**，增加QPS，从而加大整个集群的吞吐量；
3、必要的模块间使用**消息队列通信**，进行模块**异步解耦**，访问量上来后，使用时间成本换取业务能够正常服务；
4、各服务模块对自身负责的同时，要做好后端依赖有效调用的判断，做到向上游模块所做的调用都是必要的调用，无冗余或无效的调用；
5、划分好**动静资源**，**静态资源使用CDN进行服务分发**。


  [1]: https://blog.csdn.net/paul123456789io/article/details/54945475
  [2]: https://blog.csdn.net/cohenxiaomiao/article/details/49337143
  [3]: https://blog.csdn.net/u012289441/article/details/45192775